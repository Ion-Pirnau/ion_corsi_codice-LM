{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUCmsjmtpJXj"
      },
      "source": [
        "## Principal Component Analysis (PCA) in Python\n",
        "\n",
        "La Principal Component Analysis (PCA) è un'analisi multivariata utilizzata per ridurre la dimensionalità di un insieme di dati, identificando le componenti principali che rappresentano la maggior parte della variazione dei dati. In Python, la libreria scikit-learn fornisce una classe PCA che può essere utilizzata per eseguire la PCA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "9uWMGU2UpAZX"
      },
      "outputs": [],
      "source": [
        "# Non è necessario eseguire \"pip install\" delle librerie su Google Colab, in\n",
        "# quanto sono già presenti nell'ambiente di sviluppo, dato il loro utilizzo\n",
        "# intensivo in Machine Learning\n",
        "\n",
        "import numpy as np\n",
        "import sklearn as sn\n",
        "import pandas as pd\n",
        "import requests\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aSn2IRHp2hp"
      },
      "source": [
        "Per questo laboratorio, utilizzeremo il dataset *decathlon*, importandolo da locale."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJxpF831pYT3"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv (\"decathlon.csv\")\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMgLU-31vXY5"
      },
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fJAXmEWvfs5"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lD1Bb-nVvm3w"
      },
      "outputs": [],
      "source": [
        "df.select_dtypes([\"object\"]).describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKGxW82Dt5t5"
      },
      "source": [
        "Prima di applicare la PCA, è importante standardizzare le variabili numeriche."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFj_d8RRt5Ad"
      },
      "outputs": [],
      "source": [
        "variabili_numeriche = list(df.columns[1:-1])\n",
        "print(variabili_numeriche)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "7k32dfI0p9we"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(df[variabili_numeriche])\n",
        "scaled_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKMYzilOv-_T"
      },
      "source": [
        "Andiamo ad eseguire la PCA e a mostrare la varianza spiegata per ogni compontente principale mantenuta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVeJ-K76vBr7"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pca = PCA().fit(scaled_data)\n",
        "\n",
        "# Crea un grafico della varianza spiegata per ogni componente\n",
        "plt.plot(range(1, pca.n_components_ + 1), pca.explained_variance_ratio_, marker='o')\n",
        "plt.xlabel('Componenti della PCA')\n",
        "plt.ylabel('Varianza spiegata')\n",
        "plt.title(\"Risultati della PCA\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bC47mSG5w3wZ"
      },
      "source": [
        "Ora applichiamo la PCA mantenendo le prime **2** componenti principali e\n",
        "\n",
        "*   Voce elenco\n",
        "*   Voce elenco\n",
        "\n",
        "mappiamo i record nel nuovo spazio vettoriale generato dalla PCA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "zs-yoGJ4v2-L"
      },
      "outputs": [],
      "source": [
        "# Applica la PCA per ridurre la dimensionalità dei dati\n",
        "pca = PCA(n_components=2).fit(scaled_data)\n",
        "pca_data = pca.transform(scaled_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4OjJzkZwlab"
      },
      "outputs": [],
      "source": [
        "# Quantifichiamo  la percentuale di varianza spiegata da ciascuno delle componenti.\n",
        "print(pca.explained_variance_ratio_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWKTcPGCyPHw"
      },
      "outputs": [],
      "source": [
        "#Verifichiamo il coefficienti degli autovalori\n",
        "eigenvalues = pca.explained_variance_\n",
        "n_samples = scaled_data.shape[0]\n",
        "cov_matrix = np.dot(scaled_data.T, scaled_data) / n_samples\n",
        "for eigenvalue, eigenvector in zip(eigenvalues, pca.components_):\n",
        "    print(np.dot(eigenvector.T, np.dot(cov_matrix, eigenvector)))\n",
        "    print(eigenvalue)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFURJVZWxGw5"
      },
      "source": [
        "Ora, creiamo un grafico delle osservazioni nella PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1XkCbk1xHOB"
      },
      "outputs": [],
      "source": [
        "# crea una mappa etichetta-->codice colore\n",
        "unique_labels = np.unique(df[\"Competition\"])\n",
        "colors = plt.cm.tab20(np.linspace(0, 1, len(unique_labels)))\n",
        "label_to_color = dict(zip(unique_labels, colors))\n",
        "\n",
        "# genera il grafico\n",
        "fig, ax = plt.subplots()\n",
        "for label in unique_labels:\n",
        "    mask = (df[\"Competition\"] == label).values\n",
        "    ax.scatter(pca_data[mask, 0], pca_data[mask, 1], color=label_to_color[label], label=label)\n",
        "\n",
        "ax.set_xlabel('Componente 1')\n",
        "ax.set_ylabel('Componente 2')\n",
        "\n",
        "ax.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RSkj0Iruz9t"
      },
      "source": [
        "Possiamo visualizzare ogni attributo in un grafico 2D il cui asse x indica il  contributo rispetto prima componente e l'asse y rispetto alla seconda componente. Visualizziamo le proiezioni."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06cqNFISSmc5"
      },
      "source": [
        "# Come identificare l'importanza di ogni caratteristica originale\n",
        "Per identificare l'importanza di ogni feature di ciascun componente possiamo utilizzare utilizzare l'attributo ***components_***.\n",
        "\n",
        "Il risultato è un array  in cui le righe rappresentano i componenti e le colonne rappresentano le caratteristiche originali.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLU6BQckS-C4",
        "outputId": "2a9a7821-419c-4e59-b424-7bd4388334a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.32462717 0.34651451 0.28038448 0.26949298 0.31872084 0.3224588\n",
            "  0.24267251 0.06639577 0.14621541 0.04809361 0.35809724 0.45001821]\n",
            " [0.11949296 0.25237393 0.46413427 0.27269463 0.42042142 0.15540646\n",
            "  0.46898486 0.1528422  0.24403309 0.35562852 0.04480845 0.00118215]]\n"
          ]
        }
      ],
      "source": [
        "print(abs(pca.components_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NE3we5_9UEOl"
      },
      "source": [
        "Questo valore ci dice \"quanto\" ogni caratteristica influenza ciascuna componente.\n",
        "\n",
        "Quindi più alto è il valore (in valore assoluto), maggiore è l'influenza sulla componente principale.\n",
        "\n",
        "Qui possiamo stimare che la dodicesima caratteristica ha spiegato il 45% della prima componente principale e la settima caratteristica ha spiegato il 47% della seconda componente principale."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJ7mkuHCkjSs"
      },
      "source": [
        "Possiamo creare una rappresentazione più compatta delle informazioni di importanza degli attributi rispetto alle componenti"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-STZifJkqlU"
      },
      "outputs": [],
      "source": [
        "ax = sns.heatmap(pca.components_,\n",
        "                 cmap='YlGnBu',\n",
        "                 yticklabels=[ \"PCA\"+str(x) for x in range(1,pca.n_components_+1)],\n",
        "                 xticklabels=list(variabili_numeriche),\n",
        "                 cbar_kws={\"orientation\": \"vertical\"})\n",
        "ax.set_aspect(\"equal\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUDGdYCLtuly"
      },
      "source": [
        "Valori positivi e negativi all'interno di pca.n_components_ riflettono la correlazione positiva e negativa delle variabili con le componenti principali."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCTGzWk5oy4S"
      },
      "outputs": [],
      "source": [
        "loadings = pca.components_\n",
        "num_pc = pca.n_features_in_\n",
        "pc_list = [\"PC\"+str(i) for i in list(range(1, num_pc+1))]\n",
        "loadings_df = pd.DataFrame.from_dict(dict(zip(pc_list, loadings)))\n",
        "loadings_df\n",
        "loadings_df['variable'] = variabili_numeriche\n",
        "loadings_df = loadings_df.set_index('variable')\n",
        "loadings_df\n",
        "import matplotlib.pyplot as plt\n",
        "ax = sns.heatmap(loadings_df, annot=True, cmap='Spectral')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLTzL78_soF4"
      },
      "outputs": [],
      "source": [
        "pcs = pca.components_\n",
        "fig = plt.figure(figsize=(6, 5))\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "ax.set_xlim([-1, 1])\n",
        "ax.set_ylim([-1, 1])\n",
        "\n",
        "for i, (x, y) in enumerate(zip(pcs[0, :], pcs[1, :])):\n",
        "    # plot line between origin and point (x, y)\n",
        "    ax.plot([0, x], [0, y], color='k')\n",
        "    # display the label of the point\n",
        "    ax.text(x, y, df.columns[i], fontsize='10')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-oXhVaqzApe"
      },
      "source": [
        "## Assignment\n",
        "\n",
        "- Analizza il dataset IRIS:\n",
        "  - Quante componenti sono necessarie per spiegare almeno il 95% della varianza nei dati?\n",
        "  - In un nuovo spazio di rappresentazione, definito dalle componenti principali sopra determinate, i dati sono separabili rispetto alle classi?\n",
        "  "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
